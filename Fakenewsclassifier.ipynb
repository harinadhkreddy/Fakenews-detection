{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fakenewsclassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFjNcjZi1epe17dlIw4Pnz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EuMV7EHpoOF"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgCYpF4BpkYz"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import seaborn as sb"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTrk7igBrCzm",
        "outputId": "90ac2fd9-ef01-45a4-9a1c-83c74b803597"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYgkU6kxrbzZ",
        "outputId": "69819070-450e-4b3b-93ab-24998a968bdd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0MfBiptrn5p"
      },
      "source": [
        "train_news = pd.read_csv('/content/drive/My Drive/data/fakeNews/train.csv')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksQ0wdfNsIfO"
      },
      "source": [
        "test_news = pd.read_csv('/content/drive/My Drive/data/fakeNews/test.csv')\n",
        "valid_news = pd.read_csv('/content/drive/My Drive/data/fakeNews/valid.csv')\n",
        "valid_news = valid_news[:-1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBGA5KNftOyc"
      },
      "source": [
        "#data observations\n",
        "def data_obs():\n",
        "  print(\"Training data set\")\n",
        "  print(train_news.shape)\n",
        "  print(train_news.head(10))\n",
        "  print(\"------------------------------------\")\n",
        "  print(\"Testing data set\")\n",
        "  print(test_news.shape)\n",
        "  print(test_news.head(10))\n",
        "  print(\"------------------------------------\")  \n",
        "  print(\"Validation data set\")\n",
        "  print(valid_news.shape)\n",
        "  print(valid_news.head(10))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VimempXty4b",
        "outputId": "455afb6d-082c-495e-8822-fc64b22d06ed"
      },
      "source": [
        "data_obs()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data set\n",
            "(10240, 2)\n",
            "                                           Statement  Label\n",
            "0  Says the Annies List political group supports ...  False\n",
            "1  When did the decline of coal start? It started...   True\n",
            "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3  Health care reform legislation is likely to ma...  False\n",
            "4  The economic turnaround started at the end of ...   True\n",
            "5  The Chicago Bears have had more starting quart...   True\n",
            "6  Jim Dunnam has not lived in the district he re...  False\n",
            "7  I'm the only person on this stage who has work...   True\n",
            "8  However, it took $19.5 million in Oregon Lotte...   True\n",
            "9  Says GOP primary opponents Glenn Grothman and ...   True\n",
            "------------------------------------\n",
            "Testing data set\n",
            "(2551, 2)\n",
            "                                           Statement  Label\n",
            "0  Building a wall on the U.S.-Mexico border will...   True\n",
            "1  Wisconsin is on pace to double the number of l...  False\n",
            "2  Says John McCain has done nothing to help the ...  False\n",
            "3  Suzanne Bonamici supports a plan that will cut...   True\n",
            "4  When asked by a reporter whether hes at the ce...  False\n",
            "5  Over the past five years the federal governmen...   True\n",
            "6  Says that Tennessee law requires that schools ...   True\n",
            "7  Says Vice President Joe Biden \"admits that the...  False\n",
            "8  Donald Trump is against marriage equality. He ...   True\n",
            "9  We know that more than half of Hillary Clinton...  False\n",
            "------------------------------------\n",
            "Validation data set\n",
            "(2570, 2)\n",
            "                                           Statement  Label\n",
            "0  We have less Americans working now than in the...  FALSE\n",
            "1  When Obama was sworn into office, he DID NOT u...  FALSE\n",
            "2  Says Having organizations parading as being so...  FALSE\n",
            "3     Says nearly half of Oregons children are poor.   TRUE\n",
            "4  On attacks by Republicans that various program...   TRUE\n",
            "5  Says when armed civilians stop mass shootings ...  FALSE\n",
            "6  Says Tennessee is providing millions of dollar...   TRUE\n",
            "7  The health care reform plan would set limits s...  FALSE\n",
            "8  Says Donald Trump started his career back in 1...   TRUE\n",
            "9  Bill White has a long history of trying to lim...   TRUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR-vkpHFuU-u"
      },
      "source": [
        "#distribution of classes for prediction\n",
        "def create_distribution(dataFile):\n",
        "  return sb.countplot(x='Label',data=dataFile, palette='hls')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "F5A8gBPJu3Jm",
        "outputId": "e4647595-cdb6-44d0-fd3e-6d129740a2fd"
      },
      "source": [
        "#by calling below we can see that training, test and valid data seems to be failry evenly distributed between the classes\n",
        "create_distribution(train_news)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fecb6f92590>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "HbxBMtkfvLpF",
        "outputId": "8d168e3e-bc79-4192-a55c-758db8d0d3cd"
      },
      "source": [
        "create_distribution(test_news)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fecb68ab950>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "IuJ1BmzmvOvZ",
        "outputId": "15be5343-86f5-4422-99eb-244ab59da7de"
      },
      "source": [
        "create_distribution(valid_news)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fecb6775c50>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATgklEQVR4nO3dfZClZXnn8e9PRkBDwmuHwMyQoXTKXZIosl2ErFspynERXOMQoxaUrqOSjNYSjdEsYnZrYbWsTSquLGDWOBteLQo1GJdJil12grgmVUAYBJGXuHQhyExARiAkBNRgrv3j3BOObffcPUOfc3qmv5+qU/08132f51zdh+kfz8t5OlWFJEm78oJJNyBJWvoMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdY0sLJJcmuTRJHfNMfbBJJXkiLaeJBclmUlyZ5IThuZuSHJfe2wYVb+SpPmNcs/icuDU2cUkq4FTgG8NlU8D1rbHRuBTbe5hwHnAzwMnAuclOXSEPUuS5jCysKiqrwCPzzF0AXAOMPxpwPXAlTVwM3BIkqOA1wJbqurxqnoC2MIcASRJGq0V43yxJOuB7VX1tSTDQyuBh4bWt7XafPVdOuKII2rNmjXPu19JWk5uu+2271TV1FxjYwuLJC8GfpvBIahRbH8jg0NYHHPMMWzdunUULyNJ+6wkD843Ns6roV4CHAt8LckDwCrgq0l+CtgOrB6au6rV5qv/iKraVFXTVTU9NTVnMEqS9tDYwqKqvl5VP1lVa6pqDYNDSidU1SPAZuDt7aqok4Anq+ph4HrglCSHthPbp7SaJGmMRnnp7NXATcDLkmxLctYupl8H3A/MAP8D+HcAVfU48FHg1vb4SKtJksYo++Ityqenp8tzFpK0e5LcVlXTc435CW5JUpdhIUnqMiwkSV2GhSSpy7CQJHWN9XYf0mJ7z9b3TbqFfd4fTF806Ra0BLhnIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkrr8exbA1ve9Z9It7POmL/qDSbcg6XkY2Z5FkkuTPJrkrqHa7yX5qyR3JvlikkOGxj6cZCbJN5K8dqh+aqvNJDl3VP1KkuY3ysNQlwOnzqptAX62ql4O/D/gwwBJjgPOAH6mPee/J9kvyX7A7wOnAccBZ7a5kqQxGllYVNVXgMdn1f5PVT3bVm8GVrXl9cBnq+p7VfVNYAY4sT1mqur+qvo+8Nk2V5I0RpM8wf0u4H+15ZXAQ0Nj21ptvrokaYwmEhZJ/gPwLHDVIm5zY5KtSbbu2LFjsTYrSWICYZHkHcDrgbdWVbXydmD10LRVrTZf/UdU1aaqmq6q6ampqUXvW5KWs7GGRZJTgXOAN1TV00NDm4EzkhyQ5FhgLfCXwK3A2iTHJtmfwUnwzePsWZI0ws9ZJLkaOBk4Isk24DwGVz8dAGxJAnBzVb2nqu5O8nngHgaHp86uqh+07fw6cD2wH3BpVd09qp4lSXMbWVhU1ZlzlC/ZxfyPAR+bo34dcN0itiZJ2k3e7kOS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlrZGGR5NIkjya5a6h2WJItSe5rXw9t9SS5KMlMkjuTnDD0nA1t/n1JNoyqX0nS/Ea5Z3E5cOqs2rnADVW1FrihrQOcBqxtj43Ap2AQLsB5wM8DJwLn7QwYSdL4jCwsquorwOOzyuuBK9ryFcDpQ/Ura+Bm4JAkRwGvBbZU1eNV9QSwhR8NIEnSiI37nMWRVfVwW34EOLItrwQeGpq3rdXmq0uSxmhiJ7irqoBarO0l2Zhka5KtO3bsWKzNSpIYf1h8ux1eon19tNW3A6uH5q1qtfnqP6KqNlXVdFVNT01NLXrjkrScjTssNgM7r2jaAFw7VH97uyrqJODJdrjqeuCUJIe2E9untJokaYxWjGrDSa4GTgaOSLKNwVVNvwN8PslZwIPAW9r064DXATPA08A7Aarq8SQfBW5t8z5SVbNPmkuSRmxkYVFVZ84ztG6OuQWcPc92LgUuXcTWJEm7yU9wS5K6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdU0kLJL8ZpK7k9yV5OokByY5NsktSWaSfC7J/m3uAW19po2vmUTPkrScjT0skqwE3gdMV9XPAvsBZwC/C1xQVS8FngDOak85C3ii1S9o8yRJYzSpw1ArgBclWQG8GHgYeDVwTRu/Aji9La9v67TxdUkyxl4ladkbe1hU1Xbg48C3GITEk8BtwN9U1bNt2jZgZVteCTzUnvtsm3/4OHuWpOVuEoehDmWwt3AscDTwY8Cpi7DdjUm2Jtm6Y8eO57s5SdKQSRyGeg3wzaraUVX/APwx8CrgkHZYCmAVsL0tbwdWA7Txg4HHZm+0qjZV1XRVTU9NTY36e5CkZWUSYfEt4KQkL27nHtYB9wA3Am9qczYA17blzW2dNv6lqqox9itJy94kzlncwuBE9VeBr7ceNgEfAj6QZIbBOYlL2lMuAQ5v9Q8A5467Z0la7lb0p0CSG6pqXa+2UFV1HnDerPL9wIlzzP0u8OY9eR1J0uLYZVgkOZDBpa1HtBPTOy9Z/Qmeu1pJkrSP6+1ZvBt4P4Orlm7jubD4W+CTI+xLkrSE7DIsqupC4MIk762qi8fUkyRpiVnQOYuqujjJvwTWDD+nqq4cUV+SpCVkoSe4PwO8BLgD+EErF2BYSNIysKCwAKaB4/x8gyQtTwv9nMVdwE+NshFJ0tK10D2LI4B7kvwl8L2dxap6w0i6kiQtKQsNi/NH2YQkaWlb6NVQ/3fUjUiSlq6FXg31dwyufgLYH3gh8PdV9ROjakyStHQsdM/ix3cutzvFrgdOGlVTkqSlZbfvOlsD/xN47Qj6kSQtQQs9DPXGodUXMPjcxXdH0pEkaclZ6NVQvzS0/CzwAINDUZKkZWCh5yzeOepGJElL14LOWSRZleSLSR5tjy8kWTXq5iRJS8NCT3BfxuBvYR/dHn/SapKkZWChYTFVVZdV1bPtcTkwNcK+JElLyELD4rEkb0uyX3u8DXhslI1JkpaOhYbFu4C3AI8ADwNvAt4xop4kSUvMQi+d/QiwoaqeAEhyGPBxBiEiSdrHLXTP4uU7gwKgqh4HXrmnL5rkkCTXJPmrJPcm+YUkhyXZkuS+9vXQNjdJLkoyk+TOJCfs6etKkvbMQsPiBTt/ecM/7VksdK9kLhcC/7uq/hnwCuBe4FzghqpaC9zQ1gFOA9a2x0bgU8/jdSVJe2Chv/D/K3BTkj9q628GPrYnL5jkYOAXaec8qur7wPeTrAdObtOuAL4MfIjBJ8WvbH/S9ea2V3JUVT28J68vSdp9C9qzqKorgTcC326PN1bVZ/bwNY8FdgCXJbk9yR8m+THgyKEAeAQ4si2vBB4aev62VpMkjcmCDyVV1T3APYv0micA762qW5JcyHOHnHa+ViWpOZ89jyQbGRym4phjjlmENiVJO+32LcoXwTZgW1Xd0tavYRAe305yFED7+mgb3w6sHnr+qlb7IVW1qaqmq2p6asrPC0rSYhp7WFTVI8BDSV7WSusY7LFsBja02gbg2ra8GXh7uyrqJOBJz1dI0ng9nyuano/3Alcl2R+4H3gng+D6fJKzgAcZfAgQ4DrgdcAM8HSbK0kao4mERVXdweAPKM22bo65BZw98qYkSfOaxDkLSdJexrCQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtfEwiLJfkluT/Knbf3YJLckmUnyuST7t/oBbX2mja+ZVM+StFxNcs/iN4B7h9Z/F7igql4KPAGc1epnAU+0+gVtniRpjCYSFklWAf8G+MO2HuDVwDVtyhXA6W15fVunja9r8yVJYzKpPYv/BpwD/GNbPxz4m6p6tq1vA1a25ZXAQwBt/Mk2X5I0JmMPiySvBx6tqtsWebsbk2xNsnXHjh2LuWlJWvYmsWfxKuANSR4APsvg8NOFwCFJVrQ5q4DtbXk7sBqgjR8MPDZ7o1W1qaqmq2p6ampqtN+BJC0zYw+LqvpwVa2qqjXAGcCXquqtwI3Am9q0DcC1bXlzW6eNf6mqaowtS9Kyt5Q+Z/Eh4ANJZhick7ik1S8BDm/1DwDnTqg/SVq2VvSnjE5VfRn4clu+HzhxjjnfBd481sYkST9kKe1ZSJKWKMNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV1jD4skq5PcmOSeJHcn+Y1WPyzJliT3ta+HtnqSXJRkJsmdSU4Yd8+StNxNYs/iWeCDVXUccBJwdpLjgHOBG6pqLXBDWwc4DVjbHhuBT42/ZUla3sYeFlX1cFV9tS3/HXAvsBJYD1zRpl0BnN6W1wNX1sDNwCFJjhpz25K0rE30nEWSNcArgVuAI6vq4Tb0CHBkW14JPDT0tG2tJkkak4mFRZKDgC8A76+qvx0eq6oCaje3tzHJ1iRbd+zYsYidSpImEhZJXsggKK6qqj9u5W/vPLzUvj7a6tuB1UNPX9VqP6SqNlXVdFVNT01Nja55SVqGJnE1VIBLgHur6hNDQ5uBDW15A3DtUP3t7aqok4Anhw5XSZLGYMUEXvNVwL8Fvp7kjlb7beB3gM8nOQt4EHhLG7sOeB0wAzwNvHO87UqSxh4WVfUXQOYZXjfH/ALOHmlTkqRd8hPckqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXXtNWCQ5Nck3kswkOXfS/UjScrJXhEWS/YDfB04DjgPOTHLcZLuSpOVjrwgL4ERgpqrur6rvA58F1k+4J0laNvaWsFgJPDS0vq3VJEljsGLSDSyWJBuBjW31qSTfmGQ/I3YE8J1JN7FbLv70pDtYSvaq9+/TXDzpFpaSveq92wM/Pd/A3hIW24HVQ+urWu2fVNUmYNM4m5qUJFuranrSfWjP+P7tvZbze7e3HIa6FVib5Ngk+wNnAJsn3JMkLRt7xZ5FVT2b5NeB64H9gEur6u4JtyVJy8ZeERYAVXUdcN2k+1gilsXhtn2Y79/ea9m+d6mqSfcgSVri9pZzFpKkCTIsJijJD5LcMfRY0+rvT/LdJAcPzT05yZ/OsY3XJ7k9ydeS3JPk3a1+fpLts7Z/yLi+t+UiyeFDP99HZv3Mq329K8mf7Pz5z/VeJrk8yZva8pfbrW12bueaSXxvy0GSp3Zj7vlJfmtU21/q9ppzFvuoZ6rq+DnqZzK4AuyNwGXzPTnJCxkcQz2xqrYlOQBYMzTlgqr6+CL2q1mq6jHgeBj8MgGe2vkzT/LUzvc3yRXA2cDHFrjpt1bV1sXvWNoz7lksMUleAhwE/EcGobErP84g8B8DqKrvVdW+/GHEvdlNeNeBvUKSX0pyS9tj/7MkRw4NvyLJTUnuS/JrQ8/590luTXJnkv88gbZHzrCYrBcNHWr4YqudweDeV38OvGzWf6g/pKoeZ/B5kweTXJ3krUmG39PfHNr+jSP7LrRL7UaY69i9zwZdNfTe/d6IWtPc/gI4qapeyeDf4jlDYy8HXg38AvCfkhyd5BRgLYN72B0P/IskvzjmnkfOw1CTNddhqDOBX66qf0zyBeDNwCfn20BV/WqSnwNeA/wW8K+Bd7RhD0NN1ouS3MFgj+JeYEurz3cJ4nDdw1CTswr4XJKjgP2Bbw6NXVtVzwDPtP8BOxH4V8ApwO1tzkEMwuMr42t59NyzWELaL/21wJYkDzDYy+gdiqKqvl5VFzAIil8ZaZPaHTv/Z+CngTA4ZwGDw4aHzpp7GPv2PYf2JhcDn6yqnwPeDRw4NDY76IvBe/tfqur49nhpVV0ypl7HxrBYWs4Ezq+qNe1xNHB0kjlv7pXkoCQnD5WOBx4cQ5/aDVX1NPA+4INJVgD3MXhf/zlAe39fAdwxuS415GCeu/fchllj65McmORw4GQGF6JcD7wryUEASVYm+clxNTsuHoZaWs4AXjer9sVWvwVYl2Tb0NiZwDlJPg08A/w9zx2CgsE5i7cNrZ9eVQ8sdtPqq6rbk9wJnFlVn2nvy2VJDgT+AfjVqnpy6ClXJXmmLX+nql4z7p6XiRfP+jf1CeB84I+SPAF8CTh2aPxO4EYGd5/9aFX9NfDXLfhvSgLwFPA24NHRtz8+foJbktTlYShJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFtLz4F1LtVwYFpKkLsNCWmTetVT7IsNCWnzetVT7HG/3IS0+71qqfY5hIS2+i4FPVNXmdqPH84fGdnXX0k+Ppz1p93kYSlp83rVU+xz3LKTnx7uWalnwrrOSpC4PQ0mSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLU9f8BJ4lGu+iV+IsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3DzJrSyve_9",
        "outputId": "2759b0cb-8678-4524-9123-76510480cf70"
      },
      "source": [
        "valid_news['Label'].value_counts()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TRUE     1336\n",
              "FALSE    1232\n",
              "Label       1\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfu4gfp17XdG",
        "outputId": "57b56d68-5269-4708-e13b-b2cf6be99b7e"
      },
      "source": [
        "valid_news = valid_news[valid_news.Label != 'Label']\n",
        "valid_news['Label'].value_counts()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TRUE     1336\n",
              "FALSE    1232\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Pp7mzwIw7nyR",
        "outputId": "6e6b2ae4-ef0e-416c-9c70-dae3cdf9258b"
      },
      "source": [
        "create_distribution(valid_news)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fecb680d090>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsa3EZgg7qWg"
      },
      "source": [
        "#data integrity check (missing label values)\n",
        "\n",
        "def data_qualCheck(indata):\n",
        "\n",
        "  print(\"checking data quality\")\n",
        "  indata.isnull().sum()\n",
        "  indata.info()\n",
        "  print(\"check finished\")\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXqpuqwB9D3Q",
        "outputId": "72bb8c6f-d673-48a9-caf6-2b617a5864a8"
      },
      "source": [
        "data_qualCheck(train_news)\n",
        "data_qualCheck(test_news)\n",
        "data_qualCheck(valid_news)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking data quality\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10240 entries, 0 to 10239\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Statement  10240 non-null  object\n",
            " 1   Label      10240 non-null  bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 90.1+ KB\n",
            "check finished\n",
            "checking data quality\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2551 entries, 0 to 2550\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Statement  2551 non-null   object\n",
            " 1   Label      2551 non-null   bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 22.5+ KB\n",
            "check finished\n",
            "checking data quality\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2569 entries, 0 to 2569\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Statement  2569 non-null   object\n",
            " 1   Label      2568 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 140.2+ KB\n",
            "check finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axgPHChg-DRn",
        "outputId": "396f6214-9208-4f88-e1d5-649281ea3bd3"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbP1i3yZ9WkD"
      },
      "source": [
        "eng_stemmer = SnowballStemmer('english')\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBpSIJoS90Mk"
      },
      "source": [
        "#stemming\n",
        "\n",
        "def stem_tokens(tokens, stemmer):\n",
        "  stemmed=[]\n",
        "  for token in tokens:\n",
        "    stemmed.append(stemmer.stem(token))\n",
        "  return stemmed"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA9ktgCl-lx-"
      },
      "source": [
        "#process the data\n",
        "def process_data(data,exclude_stopword= True, stem=True):\n",
        "  tokens= [w.lower() for w in data]\n",
        "  tokens_stemmed= stem_tokens(tokens, eng_stemmer)\n",
        "  tokens_stemmed = [w for w in tokens_stemmed if w not in stopwords]\n",
        "  return tokens_stemmed\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfCddC7__oWv"
      },
      "source": [
        "# creating n grans\n",
        "\n",
        "#unigrams \n",
        "def create_unigram(words):\n",
        "  assert type(words) == list\n",
        "  return words\n",
        "\n",
        "#bigrams\n",
        "def create_bigrams(words):\n",
        "    assert type(words) == list\n",
        "    skip = 0\n",
        "    join_str = \" \"\n",
        "    Len = len(words)\n",
        "    if Len > 1:\n",
        "        lst = []\n",
        "        for i in range(Len-1):\n",
        "            for k in range(1,skip+2):\n",
        "                if i+k < Len:\n",
        "                    lst.append(join_str.join([words[i],words[i+k]]))\n",
        "    else:\n",
        "        #set it as unigram\n",
        "        lst = create_unigram(words)\n",
        "    return lst"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKc6nYJIAzDI"
      },
      "source": [
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtZ4kJJKBLD-"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgyUrOcHBU9C",
        "outputId": "bde5e94b-6c9c-4f56-ec25-510ac60fd5ba"
      },
      "source": [
        "%pip install DataPrep"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: DataPrep in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: varname<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.8.1)\n",
            "Requirement already satisfied: ipywidgets<8.0,>=7.5 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (7.6.5)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.6 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.8.2)\n",
            "Requirement already satisfied: bottleneck<2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.3.2)\n",
            "Requirement already satisfied: dask[array,dataframe,delayed]<3.0,>=2.25 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2.30.0)\n",
            "Requirement already satisfied: levenshtein<0.13.0,>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.12.0)\n",
            "Requirement already satisfied: metaphone<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.6)\n",
            "Requirement already satisfied: scipy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.4.1)\n",
            "Requirement already satisfied: nltk<4.0,>=3.5 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (3.6.3)\n",
            "Requirement already satisfied: jinja2<3.0,>=2.11 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2.11.3)\n",
            "Requirement already satisfied: python-stdnum<2.0,>=1.16 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.17)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (3.8.0)\n",
            "Requirement already satisfied: regex<2021.0.0,>=2020.10.15 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2020.11.13)\n",
            "Requirement already satisfied: pandas<2.0,>=1.1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.1.5)\n",
            "Requirement already satisfied: bokeh<3,>=2 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2.3.3)\n",
            "Requirement already satisfied: jsonpath-ng<2.0,>=1.5 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.5.3)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.48 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (4.62.3)\n",
            "Requirement already satisfied: usaddress<0.6.0,>=0.5.10 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.5.10)\n",
            "Requirement already satisfied: wordcloud<2.0,>=1.8 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.8.1)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.19.5)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (2.0.7)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (3.7.4.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (5.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (4.0.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (21.2.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (2.8.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (21.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (3.13)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (7.1.2)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (0.11.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (1.3.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (2021.11.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (5.1.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (1.0.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->DataPrep) (5.3.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3.0,>=2.11->DataPrep) (2.0.1)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<2.0,>=1.5->DataPrep) (3.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<2.0,>=1.5->DataPrep) (1.15.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0,>=7.5->DataPrep) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0,>=7.5->DataPrep) (4.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0,>=3.5->DataPrep) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0,>=3.5->DataPrep) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh<3,>=2->DataPrep) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.1->DataPrep) (2018.9)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (0.2.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (0.2.5)\n",
            "Requirement already satisfied: python-crfsuite>=0.7 in /usr/local/lib/python3.7/dist-packages (from usaddress<0.6.0,>=0.5.10->DataPrep) (0.9.7)\n",
            "Requirement already satisfied: future>=0.14 in /usr/local/lib/python3.7/dist-packages (from usaddress<0.6.0,>=0.5.10->DataPrep) (0.16.0)\n",
            "Requirement already satisfied: probableparsing in /usr/local/lib/python3.7/dist-packages (from usaddress<0.6.0,>=0.5.10->DataPrep) (0.0.1)\n",
            "Requirement already satisfied: executing in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->DataPrep) (0.8.2)\n",
            "Requirement already satisfied: pure_eval<1.0.0 in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->DataPrep) (0.2.1)\n",
            "Requirement already satisfied: asttokens<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->DataPrep) (2.0.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.12.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->DataPrep) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from wordcloud<2.0,>=1.8->DataPrep) (3.2.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0,>=3.6->DataPrep) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->DataPrep) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->DataPrep) (0.10.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (4.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpRIqLenA0mO"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "import nltk.corpus \n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models.word2vec import Word2Vec"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kL-bR5UCQH7",
        "outputId": "c029d049-ed57-47fa-b99b-95901cf372c3"
      },
      "source": [
        "!pip install DataPrep\n",
        "import dataprep"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: DataPrep in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: bottleneck<2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.3.2)\n",
            "Requirement already satisfied: pandas<2.0,>=1.1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.1.5)\n",
            "Requirement already satisfied: wordcloud<2.0,>=1.8 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.8.1)\n",
            "Requirement already satisfied: dask[array,dataframe,delayed]<3.0,>=2.25 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2.30.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.6 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.8.2)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.19.5)\n",
            "Requirement already satisfied: regex<2021.0.0,>=2020.10.15 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2020.11.13)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (3.8.0)\n",
            "Requirement already satisfied: ipywidgets<8.0,>=7.5 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (7.6.5)\n",
            "Requirement already satisfied: metaphone<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.6)\n",
            "Requirement already satisfied: nltk<4.0,>=3.5 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (3.6.3)\n",
            "Requirement already satisfied: usaddress<0.6.0,>=0.5.10 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.5.10)\n",
            "Requirement already satisfied: python-stdnum<2.0,>=1.16 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.17)\n",
            "Requirement already satisfied: scipy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.48 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (4.62.3)\n",
            "Requirement already satisfied: levenshtein<0.13.0,>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.12.0)\n",
            "Requirement already satisfied: jsonpath-ng<2.0,>=1.5 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (1.5.3)\n",
            "Requirement already satisfied: bokeh<3,>=2 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2.3.3)\n",
            "Requirement already satisfied: varname<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (0.8.1)\n",
            "Requirement already satisfied: jinja2<3.0,>=2.11 in /usr/local/lib/python3.7/dist-packages (from DataPrep) (2.11.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (21.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (3.7.4.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (5.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (4.0.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0,>=3.6->DataPrep) (1.2.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (21.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (2.8.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh<3,>=2->DataPrep) (3.13)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (2021.11.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (0.11.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (1.3.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (4.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (5.1.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (5.1.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8.0,>=7.5->DataPrep) (1.0.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->DataPrep) (5.3.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (2.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3.0,>=2.11->DataPrep) (2.0.1)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<2.0,>=1.5->DataPrep) (3.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<2.0,>=1.5->DataPrep) (1.15.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0,>=7.5->DataPrep) (4.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0,>=7.5->DataPrep) (2.6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0,>=3.5->DataPrep) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0,>=3.5->DataPrep) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh<3,>=2->DataPrep) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.1->DataPrep) (2018.9)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[array,dataframe,delayed]<3.0,>=2.25->DataPrep) (0.2.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets<8.0,>=7.5->DataPrep) (0.2.5)\n",
            "Requirement already satisfied: probableparsing in /usr/local/lib/python3.7/dist-packages (from usaddress<0.6.0,>=0.5.10->DataPrep) (0.0.1)\n",
            "Requirement already satisfied: python-crfsuite>=0.7 in /usr/local/lib/python3.7/dist-packages (from usaddress<0.6.0,>=0.5.10->DataPrep) (0.9.7)\n",
            "Requirement already satisfied: future>=0.14 in /usr/local/lib/python3.7/dist-packages (from usaddress<0.6.0,>=0.5.10->DataPrep) (0.16.0)\n",
            "Requirement already satisfied: executing in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->DataPrep) (0.8.2)\n",
            "Requirement already satisfied: pure_eval<1.0.0 in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->DataPrep) (0.2.1)\n",
            "Requirement already satisfied: asttokens<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from varname<0.9.0,>=0.8.1->DataPrep) (2.0.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.12.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->DataPrep) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from wordcloud<2.0,>=1.8->DataPrep) (3.2.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0,>=3.6->DataPrep) (2.10)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->DataPrep) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->DataPrep) (1.3.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0,>=7.5->DataPrep) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kru5bOavCngP"
      },
      "source": [
        "#we will start with simple bag of words technique \n",
        "#creating feature vector - document term matrix\n",
        "countV = CountVectorizer()\n",
        "train_count = countV.fit_transform(train_news['Statement'].values)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDiqSoBFCyYp",
        "outputId": "149e3d12-73d8-4f16-d765-ef659014ee40"
      },
      "source": [
        "print(countV)\n",
        "print(train_count)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n",
            "  (0, 9676)\t1\n",
            "  (0, 10988)\t1\n",
            "  (0, 1044)\t1\n",
            "  (0, 6639)\t1\n",
            "  (0, 8376)\t1\n",
            "  (0, 5115)\t1\n",
            "  (0, 10709)\t1\n",
            "  (0, 11036)\t1\n",
            "  (0, 11296)\t1\n",
            "  (0, 615)\t1\n",
            "  (0, 7728)\t1\n",
            "  (0, 3278)\t1\n",
            "  (1, 10988)\t1\n",
            "  (1, 11934)\t2\n",
            "  (1, 3434)\t1\n",
            "  (1, 3185)\t1\n",
            "  (1, 7672)\t1\n",
            "  (1, 2475)\t1\n",
            "  (1, 10425)\t1\n",
            "  (1, 6052)\t1\n",
            "  (1, 10426)\t2\n",
            "  (1, 7418)\t1\n",
            "  (1, 4860)\t1\n",
            "  (1, 11138)\t1\n",
            "  (1, 7674)\t1\n",
            "  :\t:\n",
            "  (10239, 10988)\t1\n",
            "  (10239, 7672)\t2\n",
            "  (10239, 11110)\t2\n",
            "  (10239, 5267)\t1\n",
            "  (10239, 7828)\t1\n",
            "  (10239, 7824)\t1\n",
            "  (10239, 1159)\t1\n",
            "  (10239, 12151)\t2\n",
            "  (10239, 6327)\t1\n",
            "  (10239, 6603)\t1\n",
            "  (10239, 11013)\t1\n",
            "  (10239, 11004)\t1\n",
            "  (10239, 3309)\t1\n",
            "  (10239, 12158)\t1\n",
            "  (10239, 11660)\t2\n",
            "  (10239, 799)\t1\n",
            "  (10239, 2568)\t1\n",
            "  (10239, 11622)\t1\n",
            "  (10239, 2549)\t1\n",
            "  (10239, 10660)\t1\n",
            "  (10239, 8996)\t1\n",
            "  (10239, 10918)\t1\n",
            "  (10239, 3989)\t1\n",
            "  (10239, 10594)\t1\n",
            "  (10239, 6853)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMB2hgZRC75f"
      },
      "source": [
        "#print training doc term matrix\n",
        "#we have matrix of size of (10240, 12196) by calling below\n",
        "def get_countVectorizer_stats():\n",
        "    \n",
        "    #vocab size\n",
        "    train_count.shape\n",
        "\n",
        "    #check vocabulary using below command\n",
        "    print(countV.vocabulary_)\n",
        "\n",
        "    #get feature names\n",
        "    print(countV.get_feature_names()[:25])\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNwgdhAEDB7h"
      },
      "source": [
        "#create tf-df frequency features\n",
        "#tf-idf \n",
        "tfidfV = TfidfTransformer()\n",
        "train_tfidf = tfidfV.fit_transform(train_count)\n",
        "\n",
        "def get_tfidf_stats():\n",
        "    train_tfidf.shape\n",
        "    #get train data feature names \n",
        "    print(train_tfidf.A[:10])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNyp6ptnDUX9",
        "outputId": "69e1fa1e-b535-4dfc-aa40-231c6ec5e9ef"
      },
      "source": [
        "nltk.download('treebank')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkAvTQ3eDG8t",
        "outputId": "c318548b-f632-469b-85e1-eaa4a980e75e"
      },
      "source": [
        "tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)\n",
        "\n",
        "\n",
        "#POS Tagging\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        "\n",
        "cutoff = int(.75 * len(tagged_sentences))\n",
        "training_sentences = train_news['Statement']\n",
        " \n",
        "print(training_sentences)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Says the Annies List political group supports ...\n",
            "1        When did the decline of coal start? It started...\n",
            "2        Hillary Clinton agrees with John McCain \"by vo...\n",
            "3        Health care reform legislation is likely to ma...\n",
            "4        The economic turnaround started at the end of ...\n",
            "                               ...                        \n",
            "10235    There are a larger number of shark attacks in ...\n",
            "10236    Democrats have now become the party of the [At...\n",
            "10237    Says an alternative to Social Security that op...\n",
            "10238    On lifting the U.S. Cuban embargo and allowing...\n",
            "10239    The Department of Veterans Affairs has a manua...\n",
            "Name: Statement, Length: 10240, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC2BoMAkDbQk"
      },
      "source": [
        "#training POS tagger based on words\n",
        "def features(sentence, index):\n",
        "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
        "    return {\n",
        "        'word': sentence[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
        "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
        "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
        "        'prefix-1': sentence[index][0],\n",
        "        'prefix-2': sentence[index][:2],\n",
        "        'prefix-3': sentence[index][:3],\n",
        "        'suffix-1': sentence[index][-1],\n",
        "        'suffix-2': sentence[index][-2:],\n",
        "        'suffix-3': sentence[index][-3:],\n",
        "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "        'has_hyphen': '-' in sentence[index],\n",
        "        'is_numeric': sentence[index].isdigit(),\n",
        "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
        "    }"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks_LBxjADg0Z",
        "outputId": "1fb25215-4c0b-498f-d193-99501e9a4b6f"
      },
      "source": [
        "#helper function to strip tags from tagged corpus\t\n",
        "def untag(tagged_sentence):\n",
        "    return [w for w, t in tagged_sentence]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Word2Vec(training_sentences, size=100) # x be tokenized text\n",
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "collecting all words and their counts\n",
            "Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "PROGRESS: at sentence #10000, processed 1068447 words, keeping 92 word types\n",
            "collected 93 word types from a corpus of 1094742 raw words and 10240 sentences\n",
            "Loading a fresh vocabulary\n",
            "effective_min_count=5 retains 83 unique words (89% of original 93, drops 10)\n",
            "effective_min_count=5 leaves 1094719 word corpus (99% of original 1094742, drops 23)\n",
            "deleting the raw counts dictionary of 93 items\n",
            "sample=0.001 downsamples 28 most-common words\n",
            "downsampling leaves estimated 243591 word corpus (22.3% of prior 1094719)\n",
            "estimated required memory for 83 words and 100 dimensions: 107900 bytes\n",
            "resetting layer weights\n",
            "training model with 3 workers on 83 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "worker thread finished; awaiting finish of 2 more threads\n",
            "worker thread finished; awaiting finish of 1 more threads\n",
            "worker thread finished; awaiting finish of 0 more threads\n",
            "EPOCH - 1 : training on 1094742 raw words (243404 effective words) took 0.4s, 569051 effective words/s\n",
            "worker thread finished; awaiting finish of 2 more threads\n",
            "worker thread finished; awaiting finish of 1 more threads\n",
            "worker thread finished; awaiting finish of 0 more threads\n",
            "EPOCH - 2 : training on 1094742 raw words (243425 effective words) took 0.4s, 552393 effective words/s\n",
            "worker thread finished; awaiting finish of 2 more threads\n",
            "worker thread finished; awaiting finish of 1 more threads\n",
            "worker thread finished; awaiting finish of 0 more threads\n",
            "EPOCH - 3 : training on 1094742 raw words (243053 effective words) took 0.4s, 576098 effective words/s\n",
            "worker thread finished; awaiting finish of 2 more threads\n",
            "worker thread finished; awaiting finish of 1 more threads\n",
            "worker thread finished; awaiting finish of 0 more threads\n",
            "EPOCH - 4 : training on 1094742 raw words (243108 effective words) took 0.4s, 570581 effective words/s\n",
            "worker thread finished; awaiting finish of 2 more threads\n",
            "worker thread finished; awaiting finish of 1 more threads\n",
            "worker thread finished; awaiting finish of 0 more threads\n",
            "EPOCH - 5 : training on 1094742 raw words (244011 effective words) took 0.4s, 552713 effective words/s\n",
            "training on a 5473710 raw words (1217001 effective words) took 2.2s, 550384 effective words/s\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maSVOzP_EP_O"
      },
      "source": [
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(word2vec.itervalues().next())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjXZsBwEEd5c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLMMLa51ETX_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CejutwyEmeu",
        "outputId": "f0ef9f77-cb3e-407b-afc6-787c6767fa24"
      },
      "source": [
        "#string to test\n",
        "doc_new = ['obama is running for president in 2016']\n",
        "\n",
        "#the feature selection has been done in FeatureSelection.py module. here we will create models using those features for prediction\n",
        "\n",
        "#first we will use bag of words techniques\n",
        "\n",
        "#building classifier using naive bayes \n",
        "nb_pipeline = Pipeline([\n",
        "        ('NBCV',countV),\n",
        "        ('nb_clf',MultinomialNB())])\n",
        "\n",
        "nb_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_nb = nb_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_nb == test_news['Label'])\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6072128577028616"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyaJLAqKEuMT",
        "outputId": "bdf8c4a1-524b-49a7-abb3-13134953f802"
      },
      "source": [
        "#building classifier using logistic regression\n",
        "logR_pipeline = Pipeline([\n",
        "        ('LogRCV',countV),\n",
        "        ('LogR_clf',LogisticRegression())\n",
        "        ])\n",
        "\n",
        "logR_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR = logR_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR == test_news['Label'])\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6013328106624853"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmL3z0Z4FXQ1",
        "outputId": "0720ccae-3eeb-4b05-8d20-f78af8fe2451"
      },
      "source": [
        "#building Linear SVM classfier\n",
        "svm_pipeline = Pipeline([\n",
        "        ('svmCV',countV),\n",
        "        ('svm_clf',svm.LinearSVC())\n",
        "        ])\n",
        "\n",
        "svm_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_svm = svm_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_svm == test_news['Label'])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5723245785966288"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWG14xnAFhbK",
        "outputId": "8720ad49-4020-43a8-8e16-97b0dabf6ea6"
      },
      "source": [
        "#using SVM Stochastic Gradient Descent on hinge loss\n",
        "sgd_pipeline = Pipeline([\n",
        "        ('svm2CV',countV),\n",
        "        ('svm2_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3))\n",
        "        ])\n",
        "\n",
        "sgd_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_sgd = sgd_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_sgd == test_news['Label'])\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6162289298314386"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_qGFz8yFxYT",
        "outputId": "e7789ac9-9d6f-47ba-93cb-386f5854fec2"
      },
      "source": [
        "#random forest\n",
        "random_forest = Pipeline([\n",
        "        ('rfCV',countV),\n",
        "        ('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))\n",
        "        ])\n",
        "    \n",
        "random_forest.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf = random_forest.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf == test_news['Label'])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.631125049000392"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCzqkeI2F8F3"
      },
      "source": [
        "#User defined functon for K-Fold cross validatoin\n",
        "def build_confusion_matrix(classifier):\n",
        "    \n",
        "    k_fold = KFold(n_splits=5)\n",
        "    scores = []\n",
        "    confusion = np.array([[0,0],[0,0]])\n",
        "\n",
        "    for train_ind, test_ind in k_fold.split(train_news):\n",
        "        train_text = train_news.iloc[train_ind]['Statement'] \n",
        "        train_y = train_news.iloc[train_ind]['Label']\n",
        "    \n",
        "        test_text = train_news.iloc[test_ind]['Statement']\n",
        "        test_y = train_news.iloc[test_ind]['Label']\n",
        "        \n",
        "        classifier.fit(train_text,train_y)\n",
        "        predictions = classifier.predict(test_text)\n",
        "        \n",
        "        confusion += confusion_matrix(test_y,predictions)\n",
        "        score = f1_score(test_y,predictions)\n",
        "        scores.append(score)\n",
        "    \n",
        "    return (print('Total statements classified:', train_news),\n",
        "    print('Score:', sum(scores)/len(scores)),\n",
        "    print('score length', len(scores)),\n",
        "    print('Confusion matrix:'),\n",
        "    print(confusion))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U88BODVDHjHw",
        "outputId": "16f756f1-36d4-4778-f9ad-f7225d2c1f9e"
      },
      "source": [
        "#K-fold cross validation for all classifiers\n",
        "build_confusion_matrix(nb_pipeline)\n",
        "build_confusion_matrix(logR_pipeline)\n",
        "build_confusion_matrix(svm_pipeline)\n",
        "build_confusion_matrix(sgd_pipeline)\n",
        "build_confusion_matrix(random_forest)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.66961153965076\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2118 2370]\n",
            " [1664 4088]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.6466692934443682\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2254 2234]\n",
            " [1936 3816]]\n",
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.6104687487924283\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2260 2228]\n",
            " [2246 3506]]\n",
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.6553837240422247\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2236 2252]\n",
            " [1848 3904]]\n",
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.699196943746862\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[1798 2690]\n",
            " [1214 4538]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvRXekeOH8Nl",
        "outputId": "9a25d73e-9460-4684-8774-4ff4322e4992"
      },
      "source": [
        "##Now using n-grams\n",
        "#naive-bayes classifier\n",
        "nb_pipeline_ngram = Pipeline([\n",
        "        ('nb_tfidf',tfidf_ngram),\n",
        "        ('nb_clf',MultinomialNB())])\n",
        "\n",
        "nb_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_nb_ngram = nb_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_nb_ngram == test_news['Label'])\n",
        "\n",
        "\n",
        "#logistic regression classifier\n",
        "logR_pipeline_ngram = Pipeline([\n",
        "        ('LogR_tfidf',tfidf_ngram),\n",
        "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
        "        ])\n",
        "\n",
        "logR_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR_ngram = logR_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR_ngram == test_news['Label'])\n",
        "\n",
        "\n",
        "#linear SVM classifier\n",
        "svm_pipeline_ngram = Pipeline([\n",
        "        ('svm_tfidf',tfidf_ngram),\n",
        "        ('svm_clf',svm.LinearSVC())\n",
        "        ])\n",
        "\n",
        "svm_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_svm_ngram = svm_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_svm_ngram == test_news['Label'])\n",
        "\n",
        "\n",
        "#sgd classifier\n",
        "sgd_pipeline_ngram = Pipeline([\n",
        "         ('sgd_tfidf',tfidf_ngram),\n",
        "         ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3))\n",
        "         ])\n",
        "\n",
        "sgd_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_sgd_ngram = sgd_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_sgd_ngram == test_news['Label'])\n",
        "\n",
        "\n",
        "#random forest classifier\n",
        "random_forest_ngram = Pipeline([\n",
        "        ('rf_tfidf',tfidf_ngram),\n",
        "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
        "        ])\n",
        "    \n",
        "random_forest_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf_ngram = random_forest_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf_ngram == test_news['Label'])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6032928263426107"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cimZoCI5Ixu0",
        "outputId": "ea6daba6-2d42-411e-d2c1-0c07d66bdbe5"
      },
      "source": [
        "#K-fold cross validation for all classifiers\n",
        "build_confusion_matrix(nb_pipeline_ngram)\n",
        "build_confusion_matrix(logR_pipeline_ngram)\n",
        "build_confusion_matrix(svm_pipeline_ngram)\n",
        "build_confusion_matrix(sgd_pipeline_ngram)\n",
        "build_confusion_matrix(random_forest_ngram)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.7224053159841455\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[ 758 3730]\n",
            " [ 390 5362]]\n",
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.7044355553757985\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[1580 2908]\n",
            " [1043 4709]]\n",
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.6790920142902143\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2016 2472]\n",
            " [1524 4228]]\n",
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.7190643331130575\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[   5 4483]\n",
            " [   6 5746]]\n",
            "Total statements classified:                                                Statement  Label\n",
            "0      Says the Annies List political group supports ...  False\n",
            "1      When did the decline of coal start? It started...   True\n",
            "2      Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3      Health care reform legislation is likely to ma...  False\n",
            "4      The economic turnaround started at the end of ...   True\n",
            "...                                                  ...    ...\n",
            "10235  There are a larger number of shark attacks in ...   True\n",
            "10236  Democrats have now become the party of the [At...   True\n",
            "10237  Says an alternative to Social Security that op...   True\n",
            "10238  On lifting the U.S. Cuban embargo and allowing...  False\n",
            "10239  The Department of Veterans Affairs has a manua...  False\n",
            "\n",
            "[10240 rows x 2 columns]\n",
            "Score: 0.6624886112400146\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2005 2483]\n",
            " [1673 4079]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoxvVtovIjsc",
        "outputId": "72e94c5a-110e-4a8a-e5cb-d1a358301095"
      },
      "source": [
        "print(classification_report(test_news['Label'], predicted_nb_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_LogR_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_svm_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_sgd_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_rf_ngram))\n",
        "\n",
        "test_news['Label'].shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.72      0.19      0.30      1169\n",
            "        True       0.58      0.94      0.71      1382\n",
            "\n",
            "    accuracy                           0.59      2551\n",
            "   macro avg       0.65      0.56      0.51      2551\n",
            "weighted avg       0.64      0.59      0.52      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.64      0.39      0.49      1169\n",
            "        True       0.61      0.81      0.70      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.62      0.60      0.59      2551\n",
            "weighted avg       0.62      0.62      0.60      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.61      0.47      0.53      1169\n",
            "        True       0.62      0.74      0.68      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.61      0.61      0.60      2551\n",
            "weighted avg       0.62      0.62      0.61      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.00      0.00      0.00      1169\n",
            "        True       0.54      1.00      0.70      1382\n",
            "\n",
            "    accuracy                           0.54      2551\n",
            "   macro avg       0.27      0.50      0.35      2551\n",
            "weighted avg       0.29      0.54      0.38      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.58      0.49      0.53      1169\n",
            "        True       0.62      0.70      0.66      1382\n",
            "\n",
            "    accuracy                           0.60      2551\n",
            "   macro avg       0.60      0.59      0.59      2551\n",
            "weighted avg       0.60      0.60      0.60      2551\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2551,)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA_7EOQ7Mens",
        "outputId": "369cb7e5-e45b-4f32-d891-5ae6f496dbe4"
      },
      "source": [
        "\"\"\"\n",
        "Out of all the models fitted, we would take 2 best performing model. we would call them candidate models\n",
        "from the confusion matrix, we can see that random forest and logistic regression are best performing \n",
        "in terms of precision and recall (take a look into false positive and true negative counts which appeares\n",
        "to be low compared to rest of the models)\n",
        "\"\"\"\n",
        "\n",
        "#grid-search parameter optimization\n",
        "#random forest classifier parameters\n",
        "parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'rf_tfidf__use_idf': (True, False),\n",
        "               'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([1.47371435, 1.46537452, 1.92311239, 1.949541  , 2.36867304,\n",
              "        2.38844643, 2.87391453, 2.82029543, 3.25215344, 3.25514655,\n",
              "        1.46822085, 1.47102942, 2.03265748, 1.99019284, 2.52423573,\n",
              "        2.47702751, 3.03459716, 3.00821247, 3.52114911, 3.40988774,\n",
              "        1.56988688, 1.53382115, 2.09341636, 2.09589758, 2.68555107,\n",
              "        2.59515805, 3.19185185, 3.13098707, 3.58924918, 3.53362193,\n",
              "        1.62196908, 1.60297413, 2.2239069 , 2.18518853, 2.80775857,\n",
              "        2.7969358 , 3.41390791, 3.36057611, 3.8483736 , 3.8004343 ,\n",
              "        1.71646724, 1.65541153, 2.32662983, 2.32748799, 3.03158875,\n",
              "        2.99592738, 3.67935934, 3.65008111, 4.24615498, 4.11295381,\n",
              "        1.8069489 , 1.78525081, 2.57929769, 2.50713596, 3.3767211 ,\n",
              "        3.1865561 , 3.91229367, 3.84174409, 4.36937504, 4.28643069,\n",
              "        1.87550397, 1.87222877, 2.69518728, 2.64417129, 3.44310083,\n",
              "        3.45302429, 4.13079433, 4.04824009, 4.7143599 , 4.57106829,\n",
              "        1.92601919, 1.88938699, 2.88909545, 2.79421272, 3.72063675,\n",
              "        3.71951995, 4.53421025, 4.42134581, 5.05810132, 4.99314947,\n",
              "        2.06728249, 2.02057834, 3.09253178, 3.01331019, 4.07323108,\n",
              "        4.04287367, 4.8758513 , 4.80478029, 5.45577626, 5.29871054,\n",
              "        2.15375552, 2.08023963, 3.25495901, 3.25934381, 4.26060324,\n",
              "        4.20687709, 5.0177918 , 5.05381656, 5.73434501, 5.76712832,\n",
              "        2.28666821, 2.21424098, 3.51750884, 3.43938608, 4.62250943,\n",
              "        4.43324709, 5.42269206, 5.3752202 , 6.13458548, 6.07626109,\n",
              "        2.39710517, 2.32832503, 3.6946382 , 3.65429673, 4.96383977,\n",
              "        4.85147319, 5.98906741, 5.74904952, 6.69995861, 6.580018  ,\n",
              "        2.56426659, 2.42354078, 3.98736515, 3.88452811, 5.26353002,\n",
              "        5.19257574, 6.15573716, 6.20612931, 7.11607924, 7.05218816,\n",
              "        2.67778463, 2.5436183 , 4.05482883, 4.07379904, 5.621732  ,\n",
              "        5.5372736 , 6.62666602, 6.53656659, 7.29044828, 7.56789103,\n",
              "        2.76862569, 2.66500487, 4.35522537, 4.22036352, 5.95629392,\n",
              "        5.88707194, 7.12977524, 6.99770455, 8.22973175, 8.03502965]),\n",
              " 'mean_score_time': array([0.26700292, 0.25508676, 0.34394698, 0.34473433, 0.41860657,\n",
              "        0.43755612, 0.53249726, 0.45787807, 0.52904058, 0.54643402,\n",
              "        0.27525392, 0.25278425, 0.35861073, 0.30748034, 0.42903514,\n",
              "        0.42517715, 0.46141047, 0.47078662, 0.51065722, 0.54613132,\n",
              "        0.26079307, 0.2613461 , 0.30906343, 0.30492082, 0.43895044,\n",
              "        0.44367652, 0.48635368, 0.50180526, 0.55253758, 0.58157039,\n",
              "        0.26560898, 0.26589851, 0.3267386 , 0.31953301, 0.43190308,\n",
              "        0.40903974, 0.52866144, 0.49029832, 0.52990294, 0.58805199,\n",
              "        0.25757604, 0.26982946, 0.33523793, 0.35589366, 0.41644158,\n",
              "        0.42863731, 0.50815873, 0.49952459, 0.56611691, 0.55747437,\n",
              "        0.25856028, 0.2534163 , 0.34298487, 0.34630709, 0.42149773,\n",
              "        0.41964984, 0.46659446, 0.48381157, 0.53513207, 0.5461709 ,\n",
              "        0.26589384, 0.25189996, 0.33481612, 0.32965579, 0.44093451,\n",
              "        0.40899262, 0.46723528, 0.4927866 , 0.52535548, 0.57024803,\n",
              "        0.27032223, 0.2715488 , 0.33466706, 0.33219562, 0.44080577,\n",
              "        0.43379259, 0.52707257, 0.49128327, 0.56460028, 0.60052972,\n",
              "        0.26952677, 0.26564159, 0.33574781, 0.32487893, 0.45122819,\n",
              "        0.43371   , 0.46790395, 0.44222069, 0.56356635, 0.56732235,\n",
              "        0.28148141, 0.26342287, 0.35087705, 0.31257191, 0.45197797,\n",
              "        0.4402339 , 0.5094677 , 0.4508471 , 0.46781769, 0.54148116,\n",
              "        0.26486115, 0.26467237, 0.31734862, 0.3368453 , 0.47235203,\n",
              "        0.45762811, 0.5226191 , 0.47314095, 0.61494226, 0.63310962,\n",
              "        0.26840625, 0.28399763, 0.38576622, 0.36439686, 0.45361896,\n",
              "        0.42219205, 0.48974981, 0.49927807, 0.5118073 , 0.52958775,\n",
              "        0.27835255, 0.27503643, 0.33381319, 0.36908765, 0.47528396,\n",
              "        0.42480021, 0.49579535, 0.48543997, 0.58653007, 0.57700882,\n",
              "        0.27563877, 0.2641427 , 0.41460714, 0.4253314 , 0.51069212,\n",
              "        0.43174429, 0.50632215, 0.54736524, 0.58194313, 0.59856472,\n",
              "        0.27051897, 0.27793179, 0.40769844, 0.39388824, 0.44372468,\n",
              "        0.44522262, 0.50514393, 0.50165009, 0.65925965, 0.53775125]),\n",
              " 'mean_test_score': array([0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
              "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
              "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
              "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
              "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
              "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
              "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
              "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.561 , 0.5611,\n",
              "        0.5611, 0.5611, 0.5612, 0.5611, 0.5612, 0.5611, 0.5614, 0.5614,\n",
              "        0.5613, 0.5611, 0.5614, 0.5613, 0.5614, 0.5613, 0.5613, 0.5611,\n",
              "        0.5614, 0.5614, 0.5613, 0.561 , 0.5615, 0.5614, 0.5612, 0.5613,\n",
              "        0.5613, 0.5612, 0.5627, 0.5616, 0.5627, 0.5618, 0.5622, 0.5609,\n",
              "        0.5618, 0.5614, 0.5614, 0.5618, 0.5625, 0.5623, 0.5627, 0.5626,\n",
              "        0.562 , 0.5628, 0.5618, 0.5625, 0.5614, 0.5608, 0.5638, 0.564 ,\n",
              "        0.5634, 0.5624, 0.5629, 0.563 , 0.5625, 0.562 , 0.5629, 0.5611,\n",
              "        0.5647, 0.5649, 0.5633, 0.5636, 0.5626, 0.5634, 0.5628, 0.5632,\n",
              "        0.5623, 0.5619, 0.5659, 0.5665, 0.5641, 0.5638, 0.5642, 0.5642,\n",
              "        0.5631, 0.5639, 0.5629, 0.5627, 0.5673, 0.5677, 0.565 , 0.564 ,\n",
              "        0.5645, 0.565 , 0.5641, 0.5638, 0.5631, 0.5632]),\n",
              " 'param_rf_clf__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
              "                    4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
              "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
              "                    8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
              "                    11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
              "                    12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14,\n",
              "                    14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_rf_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
              "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
              "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
              "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
              "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
              "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
              "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
              "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
              "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
              "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
              "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
              "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
              "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
              "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
              "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
              "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
              "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
              "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
              "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
              "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
              "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
              "                    (1, 4), (1, 5), (1, 5)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_rf_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 1,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 2,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 3,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 4,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 5,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 6,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 7,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 8,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 9,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 10,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 11,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 12,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 13,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 14,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 1),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 2),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 3),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 4),\n",
              "   'rf_tfidf__use_idf': False},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': True},\n",
              "  {'rf_clf__max_depth': 15,\n",
              "   'rf_tfidf__ngram_range': (1, 5),\n",
              "   'rf_tfidf__use_idf': False}],\n",
              " 'rank_test_score': array([ 77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,\n",
              "         77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,\n",
              "         77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,\n",
              "         77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,\n",
              "         77,  77,  77,  77,  77,  77,  77,  77,  77,  77, 147,  77,  77,\n",
              "         77,  73,  77,  73,  77,  56,  63,  67,  77,  56,  71,  56,  67,\n",
              "         67,  77,  56,  63,  66, 147,  55,  56,  73,  71,  67,  73,  35,\n",
              "         54,  37,  50,  46, 149,  50,  56,  63,  50,  40,  44,  35,  38,\n",
              "         47,  32,  50,  40,  56, 150,  17,  14,  21,  43,  30,  28,  40,\n",
              "         47,  29,  77,   8,   7,  23,  20,  38,  22,  32,  24,  45,  49,\n",
              "          4,   3,  12,  17,  10,  10,  27,  16,  30,  34,   2,   1,   5,\n",
              "         15,   9,   6,  12,  17,  26,  24], dtype=int32),\n",
              " 'split0_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.561 , 0.5605, 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.561 , 0.561 , 0.561 ,\n",
              "        0.5605, 0.561 , 0.561 , 0.561 , 0.561 , 0.5605, 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.5605, 0.561 , 0.5615, 0.563 , 0.562 , 0.561 ,\n",
              "        0.5615, 0.561 , 0.561 , 0.5615, 0.5605, 0.561 , 0.563 , 0.561 ,\n",
              "        0.563 , 0.5615, 0.5615, 0.5615, 0.562 , 0.561 , 0.5605, 0.561 ,\n",
              "        0.562 , 0.562 , 0.5625, 0.562 , 0.563 , 0.5615, 0.562 , 0.5615,\n",
              "        0.5625, 0.5605, 0.561 , 0.5625, 0.562 , 0.5635, 0.5625, 0.5625,\n",
              "        0.562 , 0.562 , 0.562 , 0.5605, 0.5625, 0.5635, 0.565 , 0.566 ,\n",
              "        0.562 , 0.563 , 0.563 , 0.562 , 0.5645, 0.565 , 0.564 , 0.562 ,\n",
              "        0.566 , 0.564 , 0.5635, 0.5635, 0.562 , 0.5615]),\n",
              " 'split1_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.5615,\n",
              "        0.5615, 0.561 , 0.562 , 0.5615, 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.5615, 0.561 , 0.561 , 0.5615, 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.562 , 0.563 , 0.562 , 0.561 , 0.561 , 0.5615,\n",
              "        0.561 , 0.561 , 0.561 , 0.562 , 0.5615, 0.563 , 0.5615, 0.562 ,\n",
              "        0.5615, 0.5615, 0.561 , 0.562 , 0.561 , 0.561 , 0.5625, 0.5645,\n",
              "        0.5615, 0.5615, 0.562 , 0.5635, 0.563 , 0.5625, 0.562 , 0.5615,\n",
              "        0.5635, 0.565 , 0.5635, 0.5645, 0.561 , 0.5625, 0.563 , 0.563 ,\n",
              "        0.5625, 0.562 , 0.564 , 0.5685, 0.564 , 0.564 , 0.5645, 0.5645,\n",
              "        0.564 , 0.565 , 0.562 , 0.562 , 0.5695, 0.5675, 0.5645, 0.565 ,\n",
              "        0.5665, 0.565 , 0.564 , 0.5655, 0.5625, 0.5645]),\n",
              " 'split2_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.5605, 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.5615, 0.561 , 0.5615, 0.561 , 0.561 , 0.5605,\n",
              "        0.5615, 0.561 , 0.5615, 0.561 , 0.5615, 0.562 , 0.5615, 0.561 ,\n",
              "        0.5625, 0.561 , 0.561 , 0.5605, 0.5615, 0.563 , 0.5615, 0.5615,\n",
              "        0.562 , 0.5615, 0.5655, 0.5605, 0.565 , 0.5615, 0.5635, 0.5595,\n",
              "        0.562 , 0.5625, 0.5615, 0.562 , 0.563 , 0.562 , 0.5645, 0.565 ,\n",
              "        0.56  , 0.5645, 0.561 , 0.564 , 0.5605, 0.5585, 0.566 , 0.565 ,\n",
              "        0.565 , 0.5635, 0.565 , 0.563 , 0.563 , 0.56  , 0.564 , 0.5585,\n",
              "        0.5645, 0.5665, 0.5635, 0.564 , 0.562 , 0.563 , 0.562 , 0.5635,\n",
              "        0.5625, 0.561 , 0.569 , 0.57  , 0.5625, 0.5625, 0.562 , 0.563 ,\n",
              "        0.5605, 0.564 , 0.5635, 0.564 , 0.5665, 0.5665, 0.5645, 0.5625,\n",
              "        0.561 , 0.563 , 0.561 , 0.5605, 0.561 , 0.563 ]),\n",
              " 'split3_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.5625,\n",
              "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.561 ,\n",
              "        0.5615, 0.562 , 0.5615, 0.561 , 0.562 , 0.561 , 0.561 , 0.561 ,\n",
              "        0.561 , 0.561 , 0.562 , 0.5615, 0.562 , 0.562 , 0.563 , 0.561 ,\n",
              "        0.5615, 0.561 , 0.562 , 0.5615, 0.5645, 0.5635, 0.561 , 0.562 ,\n",
              "        0.5625, 0.562 , 0.5615, 0.563 , 0.562 , 0.561 , 0.565 , 0.565 ,\n",
              "        0.563 , 0.562 , 0.562 , 0.564 , 0.5615, 0.563 , 0.5625, 0.562 ,\n",
              "        0.567 , 0.5675, 0.564 , 0.563 , 0.564 , 0.563 , 0.562 , 0.564 ,\n",
              "        0.561 , 0.5625, 0.568 , 0.5675, 0.565 , 0.564 , 0.564 , 0.5635,\n",
              "        0.564 , 0.5625, 0.5635, 0.563 , 0.569 , 0.5695, 0.5665, 0.5655,\n",
              "        0.5645, 0.565 , 0.5645, 0.565 , 0.563 , 0.5635]),\n",
              " 'split4_test_score': array([0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.5615, 0.562 , 0.562 , 0.5615, 0.5615, 0.5615,\n",
              "        0.5615, 0.5615, 0.562 , 0.5615, 0.5615, 0.5615, 0.5615, 0.562 ,\n",
              "        0.5615, 0.5615, 0.5635, 0.562 , 0.563 , 0.5615, 0.5615, 0.5615,\n",
              "        0.563 , 0.5615, 0.5615, 0.562 , 0.563 , 0.562 , 0.5635, 0.563 ,\n",
              "        0.563 , 0.5645, 0.564 , 0.562 , 0.5615, 0.5625, 0.565 , 0.5645,\n",
              "        0.5655, 0.563 , 0.563 , 0.5625, 0.562 , 0.563 , 0.564 , 0.562 ,\n",
              "        0.566 , 0.565 , 0.5645, 0.564 , 0.564 , 0.565 , 0.5645, 0.563 ,\n",
              "        0.5635, 0.562 , 0.5665, 0.566 , 0.5665, 0.565 , 0.5655, 0.564 ,\n",
              "        0.565 , 0.565 , 0.5625, 0.5625, 0.567 , 0.57  , 0.5655, 0.565 ,\n",
              "        0.5645, 0.568 , 0.5675, 0.5645, 0.567 , 0.5635]),\n",
              " 'std_fit_time': array([0.06546633, 0.04149249, 0.03215922, 0.03366902, 0.07156365,\n",
              "        0.08734675, 0.05306056, 0.04822527, 0.06833445, 0.10114719,\n",
              "        0.03636095, 0.04030725, 0.02409771, 0.01949747, 0.02374126,\n",
              "        0.04752881, 0.07341134, 0.04632279, 0.05234801, 0.03726439,\n",
              "        0.04267711, 0.04240536, 0.03115007, 0.02882151, 0.04366763,\n",
              "        0.09141505, 0.01683418, 0.02667243, 0.05424184, 0.08694652,\n",
              "        0.04801634, 0.01002525, 0.05791033, 0.04101568, 0.04301253,\n",
              "        0.06046544, 0.01879155, 0.01878916, 0.05135385, 0.06288107,\n",
              "        0.02873831, 0.03474975, 0.04566014, 0.05030058, 0.05335981,\n",
              "        0.08379818, 0.05258664, 0.05936313, 0.05265478, 0.05005406,\n",
              "        0.03266419, 0.03054491, 0.0491107 , 0.03814509, 0.06475659,\n",
              "        0.06167997, 0.05574777, 0.06605738, 0.10973348, 0.07604963,\n",
              "        0.02326817, 0.03851272, 0.06371543, 0.05314727, 0.05753939,\n",
              "        0.04582415, 0.05168848, 0.07602599, 0.09792901, 0.04620239,\n",
              "        0.05157819, 0.03557298, 0.04250008, 0.06629459, 0.05594535,\n",
              "        0.07879779, 0.14412826, 0.07201347, 0.18962982, 0.10801428,\n",
              "        0.035402  , 0.05736808, 0.05728803, 0.04360265, 0.08097557,\n",
              "        0.11466072, 0.06146841, 0.09259738, 0.12225246, 0.09473466,\n",
              "        0.03677731, 0.03203466, 0.06118249, 0.10279669, 0.04795362,\n",
              "        0.09916314, 0.12344097, 0.15362875, 0.19946578, 0.1502616 ,\n",
              "        0.03181438, 0.09376391, 0.07917733, 0.02883181, 0.05773276,\n",
              "        0.14132614, 0.14390703, 0.18532086, 0.20745445, 0.25634699,\n",
              "        0.05065456, 0.01784644, 0.11170641, 0.0909252 , 0.09769455,\n",
              "        0.12482822, 0.07868933, 0.13097415, 0.24690994, 0.0354202 ,\n",
              "        0.08132077, 0.06550762, 0.03436981, 0.04626853, 0.15594524,\n",
              "        0.21018178, 0.17483226, 0.23031474, 0.25337936, 0.30953823,\n",
              "        0.06737551, 0.08487215, 0.13626038, 0.07985215, 0.1065775 ,\n",
              "        0.22293009, 0.31700622, 0.19957247, 0.2515535 , 0.17033034,\n",
              "        0.05714513, 0.05592124, 0.15555952, 0.07159807, 0.21589749,\n",
              "        0.27746017, 0.17556212, 0.10455492, 0.16212399, 0.20649039]),\n",
              " 'std_score_time': array([0.02650774, 0.01229234, 0.0568688 , 0.04277979, 0.03880305,\n",
              "        0.00674426, 0.06121884, 0.02129248, 0.05191223, 0.06085005,\n",
              "        0.01109762, 0.04268623, 0.05732521, 0.01165554, 0.01547874,\n",
              "        0.01645615, 0.03524329, 0.0334608 , 0.04280934, 0.05726993,\n",
              "        0.01363914, 0.00486843, 0.00979696, 0.00515261, 0.01701348,\n",
              "        0.01338541, 0.05900883, 0.04985001, 0.05303688, 0.01005351,\n",
              "        0.01232521, 0.0107908 , 0.04233545, 0.04208209, 0.02525037,\n",
              "        0.03343374, 0.03122232, 0.06105426, 0.04686532, 0.07842655,\n",
              "        0.01206431, 0.02689634, 0.04427633, 0.04780806, 0.02378287,\n",
              "        0.02197154, 0.04587152, 0.04343704, 0.02708886, 0.01250953,\n",
              "        0.01260248, 0.01875501, 0.03188053, 0.0472234 , 0.01605495,\n",
              "        0.01597257, 0.01086526, 0.04220205, 0.06238911, 0.04497083,\n",
              "        0.02105283, 0.01580729, 0.04964851, 0.04703374, 0.01128243,\n",
              "        0.03905213, 0.00777538, 0.03936027, 0.06193369, 0.0519537 ,\n",
              "        0.01308974, 0.00914181, 0.03945226, 0.05392708, 0.02181632,\n",
              "        0.02063383, 0.05226182, 0.03846401, 0.05711629, 0.03932336,\n",
              "        0.01087879, 0.01225341, 0.05606593, 0.04157308, 0.01192343,\n",
              "        0.01009718, 0.04474567, 0.01678872, 0.04309629, 0.00556886,\n",
              "        0.01847798, 0.01390139, 0.04902695, 0.01745518, 0.02169999,\n",
              "        0.01414405, 0.04983929, 0.02181005, 0.00973836, 0.06874069,\n",
              "        0.01364439, 0.02172243, 0.04787439, 0.0551495 , 0.0258553 ,\n",
              "        0.02663246, 0.0580836 , 0.00880671, 0.08266565, 0.09533423,\n",
              "        0.01053168, 0.00551083, 0.04644784, 0.05348912, 0.03767126,\n",
              "        0.00825168, 0.04590273, 0.07785738, 0.06716204, 0.06739082,\n",
              "        0.01651119, 0.01395851, 0.0619815 , 0.05330887, 0.04374838,\n",
              "        0.02693208, 0.05160803, 0.10700255, 0.02373246, 0.02156074,\n",
              "        0.01613288, 0.01446608, 0.06876785, 0.02784361, 0.04669479,\n",
              "        0.02215865, 0.03666851, 0.08383108, 0.08965203, 0.04486379,\n",
              "        0.00969603, 0.02081751, 0.03748699, 0.0560273 , 0.01731973,\n",
              "        0.0354182 , 0.04488622, 0.04801179, 0.09244003, 0.12446803]),\n",
              " 'std_test_score': array([0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
              "        0.00037417, 0.0002    , 0.00031623, 0.0002    , 0.0002    ,\n",
              "        0.0002    , 0.00024495, 0.0002    , 0.00024495, 0.0002    ,\n",
              "        0.0002    , 0.00066332, 0.00024495, 0.0002    , 0.00037417,\n",
              "        0.0004    , 0.00037417, 0.0004    , 0.00024495, 0.0002    ,\n",
              "        0.00066332, 0.00037417, 0.0004    , 0.00031623, 0.00031623,\n",
              "        0.00086023, 0.00024495, 0.0004    , 0.0004    , 0.00024495,\n",
              "        0.00169115, 0.00086023, 0.001249  , 0.00067823, 0.00092736,\n",
              "        0.00073485, 0.00067823, 0.0005831 , 0.00037417, 0.00024495,\n",
              "        0.0013784 , 0.00087178, 0.00128841, 0.00135647, 0.00114018,\n",
              "        0.0014    , 0.0011225 , 0.00089443, 0.0005831 , 0.00128841,\n",
              "        0.00201494, 0.00151658, 0.00159374, 0.00073485, 0.00111355,\n",
              "        0.00070711, 0.00063246, 0.00114018, 0.00091652, 0.00131909,\n",
              "        0.00163095, 0.00239583, 0.0012083 , 0.00073485, 0.0012    ,\n",
              "        0.00086023, 0.00092736, 0.0005099 , 0.0008124 , 0.0004899 ,\n",
              "        0.00257682, 0.00327109, 0.00152971, 0.0008124 , 0.0012083 ,\n",
              "        0.00102956, 0.00162481, 0.0010198 , 0.0005831 , 0.00074833,\n",
              "        0.00180555, 0.00186011, 0.00089443, 0.00144914, 0.00192354,\n",
              "        0.00167332, 0.00208327, 0.00177764, 0.00205913, 0.0009798 ])}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYEvtuEYM5b8",
        "outputId": "74052a1d-da8e-40f6-9739-12a1c56da9a6"
      },
      "source": [
        "#logistic regression parameters\n",
        "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'LogR_tfidf__use_idf': (True, False),\n",
        "               'LogR_tfidf__smooth_idf': (True, False)\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.60706296, 0.48396392, 0.55614743, 0.49026675, 1.78417439,\n",
              "        1.90405054, 1.64494538, 1.77041464, 2.59323835, 3.17503948,\n",
              "        2.477495  , 3.30101404, 3.10719128, 3.95236163, 3.19317703,\n",
              "        3.87697959, 3.83612475, 4.55120902, 4.12474642, 4.43579116]),\n",
              " 'mean_score_time': array([0.07031407, 0.05956478, 0.06251893, 0.06466718, 0.10156622,\n",
              "        0.09952254, 0.09707322, 0.09064822, 0.1237371 , 0.1218204 ,\n",
              "        0.1325377 , 0.12786894, 0.16016054, 0.14892354, 0.15997672,\n",
              "        0.148385  , 0.17276511, 0.16327519, 0.18073659, 0.1559145 ]),\n",
              " 'mean_test_score': array([0.6046, 0.6106, 0.6055, 0.6106, 0.6142, 0.6105, 0.614 , 0.6105,\n",
              "        0.6149, 0.6103, 0.6162, 0.6103, 0.6165, 0.6097, 0.6159, 0.6097,\n",
              "        0.616 , 0.6093, 0.6151, 0.6093]),\n",
              " 'param_LogR_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
              "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
              "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_LogR_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_LogR_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False}],\n",
              " 'rank_test_score': array([20,  9, 19,  9,  7, 11,  8, 11,  6, 13,  2, 13,  1, 15,  4, 15,  3,\n",
              "        17,  5, 17], dtype=int32),\n",
              " 'split0_test_score': array([0.6135, 0.617 , 0.6125, 0.617 , 0.619 , 0.617 , 0.6175, 0.617 ,\n",
              "        0.6205, 0.6175, 0.621 , 0.6175, 0.6175, 0.6155, 0.6175, 0.6155,\n",
              "        0.614 , 0.615 , 0.6115, 0.615 ]),\n",
              " 'split1_test_score': array([0.618 , 0.6205, 0.6185, 0.6205, 0.6245, 0.623 , 0.625 , 0.623 ,\n",
              "        0.6245, 0.6165, 0.624 , 0.6165, 0.623 , 0.613 , 0.6205, 0.613 ,\n",
              "        0.622 , 0.6135, 0.619 , 0.6135]),\n",
              " 'split2_test_score': array([0.5945, 0.603 , 0.596 , 0.603 , 0.6025, 0.6015, 0.605 , 0.6015,\n",
              "        0.604 , 0.6045, 0.608 , 0.6045, 0.609 , 0.603 , 0.607 , 0.603 ,\n",
              "        0.6065, 0.601 , 0.609 , 0.601 ]),\n",
              " 'split3_test_score': array([0.599 , 0.608 , 0.5995, 0.608 , 0.6105, 0.605 , 0.6105, 0.605 ,\n",
              "        0.6125, 0.606 , 0.615 , 0.606 , 0.617 , 0.611 , 0.616 , 0.611 ,\n",
              "        0.621 , 0.6115, 0.618 , 0.6115]),\n",
              " 'split4_test_score': array([0.598 , 0.6045, 0.601 , 0.6045, 0.6145, 0.606 , 0.612 , 0.606 ,\n",
              "        0.613 , 0.607 , 0.613 , 0.607 , 0.616 , 0.606 , 0.6185, 0.606 ,\n",
              "        0.6165, 0.6055, 0.618 , 0.6055]),\n",
              " 'std_fit_time': array([0.0243432 , 0.01779042, 0.01386442, 0.03308965, 0.05532717,\n",
              "        0.05459957, 0.13758143, 0.05132226, 0.19354127, 0.1146379 ,\n",
              "        0.0632872 , 0.08314076, 0.12209315, 0.20574595, 0.18717673,\n",
              "        0.20326265, 0.37941973, 0.28727449, 0.10602736, 0.62399016]),\n",
              " 'std_score_time': array([0.00668128, 0.00098536, 0.0021353 , 0.00610983, 0.00211484,\n",
              "        0.00436515, 0.00708278, 0.01029755, 0.01069385, 0.01067615,\n",
              "        0.00381675, 0.00524615, 0.00649859, 0.00403844, 0.00711485,\n",
              "        0.00434901, 0.01233381, 0.01819709, 0.00962241, 0.02866433]),\n",
              " 'std_test_score': array([0.00933488, 0.0069383 , 0.00853815, 0.0069383 , 0.00748064,\n",
              "        0.00812404, 0.0067897 , 0.00812404, 0.00709507, 0.00553715,\n",
              "        0.00570614, 0.00553715, 0.00447214, 0.00457821, 0.00468402,\n",
              "        0.00457821, 0.00557674, 0.00525928, 0.00405463, 0.00525928])}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyKLLx60NDde",
        "outputId": "b50840eb-ce2e-454d-e7ff-91dfdeda1bbe"
      },
      "source": [
        "#Linear SVM \n",
        "parameters = {'svm_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'svm_tfidf__use_idf': (True, False),\n",
        "               'svm_tfidf__smooth_idf': (True, False),\n",
        "               'svm_clf__penalty': ('l1','l2'),\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.27562871, 0.2653419 , 0.25939837, 0.26118646, 0.70499821,\n",
              "        0.67945232, 0.69748945, 0.6868989 , 1.18233395, 1.15121217,\n",
              "        1.16899972, 1.1519433 , 1.58248491, 1.55129514, 1.60075951,\n",
              "        1.54939013, 1.96882272, 1.91851168, 1.96943369, 1.90894117,\n",
              "        0.31454673, 0.31153164, 0.31370535, 0.31600199, 0.78535776,\n",
              "        0.77593269, 0.80305181, 0.76170554, 1.29680924, 1.25848918,\n",
              "        1.31931   , 1.2697124 , 1.75566978, 1.67557788, 1.75966997,\n",
              "        1.70461693, 2.21615992, 2.1512536 , 2.20118532, 2.09079056]),\n",
              " 'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.05989451, 0.06066689, 0.0613739 , 0.05847921, 0.10028982,\n",
              "        0.09683599, 0.10558548, 0.10479226, 0.13066401, 0.12198334,\n",
              "        0.13150196, 0.13458076, 0.15861506, 0.14935889, 0.16266904,\n",
              "        0.14937153, 0.17625937, 0.17424598, 0.18146191, 0.16279302]),\n",
              " 'mean_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan, 0.5814, 0.5893, 0.5821, 0.5893,\n",
              "        0.5992, 0.5984, 0.6014, 0.5984, 0.6047, 0.6031, 0.6065, 0.6031,\n",
              "        0.6063, 0.607 , 0.6071, 0.607 , 0.6076, 0.6068, 0.6082, 0.6068]),\n",
              " 'param_svm_clf__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_svm_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
              "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
              "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5), (1, 1),\n",
              "                    (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2), (1, 2),\n",
              "                    (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4), (1, 4),\n",
              "                    (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_svm_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False, True, True, False, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_svm_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l1',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 1),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 2),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 3),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 4),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': True,\n",
              "   'svm_tfidf__use_idf': False},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': True},\n",
              "  {'svm_clf__penalty': 'l2',\n",
              "   'svm_tfidf__ngram_range': (1, 5),\n",
              "   'svm_tfidf__smooth_idf': False,\n",
              "   'svm_tfidf__use_idf': False}],\n",
              " 'rank_test_score': array([21, 23, 24, 25, 26, 27, 28, 29, 31, 39, 32, 33, 34, 35, 36, 37, 38,\n",
              "        22, 30, 40, 20, 17, 19, 17, 14, 15, 13, 15, 10, 11,  8, 11,  9,  4,\n",
              "         3,  4,  2,  6,  1,  6], dtype=int32),\n",
              " 'split0_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan, 0.5895, 0.5985, 0.5915, 0.5985,\n",
              "        0.6075, 0.6065, 0.611 , 0.6065, 0.611 , 0.607 , 0.6135, 0.607 ,\n",
              "        0.6135, 0.615 , 0.6135, 0.615 , 0.617 , 0.616 , 0.617 , 0.616 ]),\n",
              " 'split1_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan, 0.5925, 0.6025, 0.591 , 0.6025,\n",
              "        0.622 , 0.6215, 0.625 , 0.6215, 0.624 , 0.6195, 0.6265, 0.6195,\n",
              "        0.6215, 0.623 , 0.622 , 0.623 , 0.6195, 0.622 , 0.6215, 0.622 ]),\n",
              " 'split2_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan, 0.571 , 0.576 , 0.5725, 0.576 ,\n",
              "        0.585 , 0.586 , 0.588 , 0.586 , 0.59  , 0.5905, 0.589 , 0.5905,\n",
              "        0.589 , 0.591 , 0.59  , 0.591 , 0.59  , 0.5925, 0.5915, 0.5925]),\n",
              " 'split3_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan, 0.5725, 0.583 , 0.5725, 0.583 ,\n",
              "        0.5855, 0.5835, 0.586 , 0.5835, 0.5905, 0.5945, 0.593 , 0.5945,\n",
              "        0.5975, 0.5995, 0.5975, 0.5995, 0.5995, 0.598 , 0.5975, 0.598 ]),\n",
              " 'split4_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
              "           nan,    nan,    nan,    nan, 0.5815, 0.5865, 0.583 , 0.5865,\n",
              "        0.596 , 0.5945, 0.597 , 0.5945, 0.608 , 0.604 , 0.6105, 0.604 ,\n",
              "        0.61  , 0.6065, 0.6125, 0.6065, 0.612 , 0.6055, 0.6135, 0.6055]),\n",
              " 'std_fit_time': array([0.01190628, 0.00877899, 0.0076486 , 0.00930457, 0.00819232,\n",
              "        0.00486148, 0.00915969, 0.01157282, 0.01296951, 0.01304302,\n",
              "        0.01633624, 0.0082145 , 0.01600838, 0.0073678 , 0.02969423,\n",
              "        0.02768353, 0.01405789, 0.02706907, 0.01725512, 0.01788826,\n",
              "        0.0126308 , 0.0068357 , 0.00448436, 0.00799853, 0.01109192,\n",
              "        0.01079077, 0.01822707, 0.00558647, 0.02273725, 0.01899347,\n",
              "        0.01152036, 0.00659792, 0.03102399, 0.01881591, 0.01322102,\n",
              "        0.01586605, 0.0274095 , 0.01642243, 0.02442423, 0.0339384 ]),\n",
              " 'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00107591, 0.00532399, 0.0057117 , 0.00181468, 0.00414983,\n",
              "        0.00287436, 0.00607069, 0.00983321, 0.00560725, 0.00130156,\n",
              "        0.00709812, 0.00707889, 0.01150441, 0.00614262, 0.01061318,\n",
              "        0.00561611, 0.00484204, 0.01010002, 0.01465777, 0.03054616]),\n",
              " 'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.0086741 , 0.00983158, 0.00839881, 0.00983158, 0.01405916,\n",
              "        0.01407267, 0.01473228, 0.01407267, 0.01296765, 0.01017546,\n",
              "        0.01380942, 0.01017546, 0.01160431, 0.01124722, 0.01163357,\n",
              "        0.01124722, 0.01117766, 0.01094806, 0.01162583, 0.01094806])}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbnE_S6mNKzo",
        "outputId": "25bd2cfc-6d99-4ea6-a501-5dd3c9a68558"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "#running both random forest and logistic regression models again with best parameter found with GridSearch method\n",
        "random_forest_final = Pipeline([\n",
        "        ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
        "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
        "        ])\n",
        "    \n",
        "random_forest_final.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf_final = random_forest_final.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf_final == test_news['Label'])\n",
        "print(metrics.classification_report(test_news['Label'], predicted_rf_final))\n",
        "\n",
        "logR_pipeline_final = Pipeline([\n",
        "        #('LogRCV',countV_ngram),\n",
        "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
        "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
        "        ])\n",
        "\n",
        "logR_pipeline_final.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR_final = logR_pipeline_final.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR_final == test_news['Label'])\n",
        "#accuracy = 0.62\n",
        "print(metrics.classification_report(test_news['Label'], predicted_LogR_final))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.50      0.00      0.00      1169\n",
            "        True       0.54      1.00      0.70      1382\n",
            "\n",
            "    accuracy                           0.54      2551\n",
            "   macro avg       0.52      0.50      0.35      2551\n",
            "weighted avg       0.52      0.54      0.38      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.64      0.38      0.48      1169\n",
            "        True       0.61      0.82      0.70      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.62      0.60      0.59      2551\n",
            "weighted avg       0.62      0.62      0.60      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxGjCruQN7cQ"
      },
      "source": [
        "#saving best model to the disk\n",
        "model_file = 'final_model.sav'\n",
        "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SBNX9inN1JK"
      },
      "source": [
        "#Plotting learing curve\n",
        "def plot_learing_curve(pipeline,title):\n",
        "    size = 10000\n",
        "    cv = KFold(size, shuffle=True)\n",
        "    \n",
        "    X = train_news[\"Statement\"]\n",
        "    y = train_news[\"Label\"]\n",
        "    \n",
        "    pl = pipeline\n",
        "    pl.fit(X,y)\n",
        "    \n",
        "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
        "       \n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "     \n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    \n",
        "    # box-like grid\n",
        "    plt.grid()\n",
        "    \n",
        "    # plot the std deviation as a transparent range at each training set size\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    \n",
        "    # plot the average training and test score lines at each training set size\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    \n",
        "    # sizes the window for readability and displays the plot\n",
        "    # shows error from 0 to 1.1\n",
        "    plt.ylim(-.1,1.1)\n",
        "    plt.show()"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb8v96uZTyi8"
      },
      "source": [
        "#below command will plot learing curves for each of the classifiers\n",
        "plot_learing_curve(nb_pipeline_ngram,\"Naive-bayes Classifier\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veMy4OqWijnz"
      },
      "source": [
        "plot_learing_curve(logR_pipeline_ngram,\"LogisticRegression Classifier\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKeJnmk0il8E"
      },
      "source": [
        "plot_learing_curve(svm_pipeline_ngram,\"SVM Classifier\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdJ_n4soin5u"
      },
      "source": [
        "plot_learing_curve(sgd_pipeline_ngram,\"SGD Classifier\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y553-WpuiqBq"
      },
      "source": [
        "plot_learing_curve(random_forest_ngram,\"RandomForest Classifier\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "hHXgRGm8V6S8",
        "outputId": "b409495c-44d2-40ca-e7a7-a252c088d5ca"
      },
      "source": [
        "#plotting Precision-Recall curve\n",
        "def plot_PR_curve(classifier):\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(test_news['Label'], classifier)\n",
        "    average_precision = average_precision_score(test_news['Label'], classifier)\n",
        "    \n",
        "    plt.step(recall, precision, color='b', alpha=0.2,\n",
        "             where='post')\n",
        "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
        "                     color='b')\n",
        "    \n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title('2-class Random Forest Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "              average_precision))\n",
        "    \n",
        "plot_PR_curve(predicted_LogR_ngram)\n",
        "plot_PR_curve(predicted_rf_ngram)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1df14bc4a6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m               average_precision))\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mplot_PR_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_LogR_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mplot_PR_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_rf_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predicted_LogR_ngram' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BIOQD45V_PV"
      },
      "source": [
        "def show_most_informative_features(model, vect, clf, text=None, n=50):\n",
        "    # Extract the vectorizer and the classifier from the pipeline\n",
        "    vectorizer = model.named_steps[vect]\n",
        "    classifier = model.named_steps[clf]\n",
        "\n",
        "     # Check to make sure that we can perform this computation\n",
        "    if not hasattr(classifier, 'coef_'):\n",
        "        raise TypeError(\n",
        "            \"Cannot compute most informative features on {}.\".format(\n",
        "                classifier.__class__.__name__\n",
        "            )\n",
        "        )\n",
        "            \n",
        "    if text is not None:\n",
        "        # Compute the coefficients for the text\n",
        "        tvec = model.transform([text]).toarray()\n",
        "    else:\n",
        "        # Otherwise simply use the coefficients\n",
        "        tvec = classifier.coef_\n",
        "\n",
        "    # Zip the feature names with the coefs and sort\n",
        "    coefs = sorted(\n",
        "        zip(tvec[0], vectorizer.get_feature_names()),\n",
        "        reverse=True\n",
        "    )\n",
        "    \n",
        "    # Get the top n and bottom n coef, name pairs\n",
        "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
        "\n",
        "    # Create the output string to return\n",
        "    output = []\n",
        "\n",
        "    # If text, add the predicted value to the output.\n",
        "    if text is not None:\n",
        "        output.append(\"\\\"{}\\\"\".format(text))\n",
        "        output.append(\n",
        "            \"Classified as: {}\".format(model.predict([text]))\n",
        "        )\n",
        "        output.append(\"\")\n",
        "\n",
        "    # Create two columns with most negative and most positive features.\n",
        "    for (cp, fnp), (cn, fnn) in topn:\n",
        "        output.append(\n",
        "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
        "                cp, fnp, cn, fnn\n",
        "            )\n",
        "        )\n",
        "    #return \"\\n\".join(output)\n",
        "    print(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhXCBOkcWMVF"
      },
      "source": [
        "show_most_informative_features(logR_pipeline_ngram,vect='LogR_tfidf',clf='LogR_clf')\n",
        "show_most_informative_features(nb_pipeline_ngram,vect='nb_tfidf',clf='nb_clf')\n",
        "show_most_informative_features(svm_pipeline_ngram,vect='svm_tfidf',clf='svm_clf')\n",
        "show_most_informative_features(sgd_pipeline_ngram,vect='sgd_tfidf',clf='sgd_clf')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}